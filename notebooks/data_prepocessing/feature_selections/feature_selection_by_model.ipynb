{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ec59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import (RFECV, SelectKBest, mutual_info_regression, \n",
    "                                      VarianceThreshold, SelectFromModel)\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/processed/land_dataset_final_v2.csv')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5697f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('h_id')['price_per_m2']\n",
    "for stat in ['mean', 'max', 'median', 'min']:\n",
    "    df[f'h_id_price_{stat}'] = grouped.transform(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\n",
    "    'price_per_m2', 'longitude', 'latitude', 'address_subdivision',\n",
    "    'h_id', 'address_locality', 'price', 'geometry'\n",
    "], axis=1, errors='ignore')\n",
    "y = df['price_per_m2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3779573",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X_encoded = X.copy()\n",
    "X_encoded[cat_cols] = encoder.fit_transform(X[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e47a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initial filtering: Remove low-variance features\n",
    "\n",
    "variance_selector = VarianceThreshold(threshold=0.01)\n",
    "X_train_filtered = variance_selector.fit_transform(X_train)\n",
    "selected_mask = variance_selector.get_support()\n",
    "remaining_features = X_train.columns[selected_mask].tolist()\n",
    "print(f\"After variance threshold: {len(remaining_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a24d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Univariate feature selection (Filter method)\n",
    "\n",
    "univariate_selector = SelectKBest(score_func=mutual_info_regression, k=25)\n",
    "X_train_univariate = univariate_selector.fit_transform(X_train_filtered, y_train)\n",
    "univariate_mask = univariate_selector.get_support()\n",
    "remaining_features = [f for f, keep in zip(remaining_features, univariate_mask) if keep]\n",
    "print(f\"After univariate selection: {len(remaining_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d66f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Recursive Feature Elimination with Cross-Validation (Wrapper method)\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "rfe_selector = RFECV(\n",
    "    estimator=model,\n",
    "    step=1,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    min_features_to_select=15,\n",
    "    n_jobs=-1\n",
    ")\n",
    "X_train_rfe = rfe_selector.fit_transform(X_train_univariate, y_train)\n",
    "rfe_mask = rfe_selector.get_support()\n",
    "remaining_features = [f for f, keep in zip(remaining_features, rfe_mask) if keep]\n",
    "print(f\"After RFECV: {len(remaining_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Embedded method: Feature importance with regularization\n",
    "\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_rfe, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features based on importance threshold\n",
    "sfm_selector = SelectFromModel(model, threshold=\"median\", prefit=True)\n",
    "embedded_mask = sfm_selector.get_support()\n",
    "remaining_features = [f for f, keep in zip(remaining_features, embedded_mask) if keep]\n",
    "print(f\"After embedded selection: {len(remaining_features)} features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7abb026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. SHAP-based feature validation (Model interpretation)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train_rfe)\n",
    "\n",
    "# Get SHAP importance scores\n",
    "shap_importance = pd.DataFrame({\n",
    "    'feature': remaining_features,\n",
    "    'shap_importance': np.abs(shap_values).mean(0)\n",
    "}).sort_values('shap_importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93765f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features by SHAP importance\n",
    "shap_mask = shap_importance['shap_importance'] > shap_importance['shap_importance'].quantile(0.5)\n",
    "final_features = shap_importance[shap_mask]['feature'].tolist()\n",
    "print(f\"Final selected features: {len(final_features)}\")\n",
    "\n",
    "# 7. Validate selection quality\n",
    "X_train_final = X_train_rfe[:, embedded_mask][:, shap_mask]\n",
    "X_test_processed = variance_selector.transform(X_test)\n",
    "X_test_processed = univariate_selector.transform(X_test_processed)\n",
    "X_test_processed = rfe_selector.transform(X_test_processed)\n",
    "X_test_final = sfm_selector.transform(X_test_processed)[:, shap_mask]\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "model.fit(X_train_final, y_train)\n",
    "score = model.score(X_test_final, y_test)\n",
    "print(f\"Validation RÂ² with selected features: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected categorical and numerical features\n",
    "cat_selected = [col for col in final_features if col in cat_cols]\n",
    "num_selected = [col for col in final_features if col not in cat_cols]\n",
    "\n",
    "# Create base dataframe with selected features from ORIGINAL data (not encoded)\n",
    "X_selected = X[final_features].copy()\n",
    "\n",
    "# One-hot encode categorical features\n",
    "if cat_selected:\n",
    "    ohe = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "    ohe.fit(X_selected[cat_selected])\n",
    "    \n",
    "    # Transform categorical features\n",
    "    X_ohe = ohe.transform(X_selected[cat_selected])\n",
    "    \n",
    "    # Create DataFrame for encoded features\n",
    "    ohe_columns = ohe.get_feature_names_out(cat_selected)\n",
    "    X_ohe_df = pd.DataFrame(X_ohe, columns=ohe_columns, index=X_selected.index)\n",
    "    \n",
    "    # Combine with numerical features\n",
    "    X_final = pd.concat([X_selected[num_selected], X_ohe_df], axis=1)\n",
    "else:\n",
    "    X_final = X_selected.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df87b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add target and save\n",
    "final_dataset = pd.concat([X_final, y], axis=1)\n",
    "final_dataset.to_csv(\n",
    "    \"../../../data/preprocessed/selected_features_dataset.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Save feature selection report and encoders\n",
    "shap_importance.to_csv(\"feature_selection_report.csv\", index=False)\n",
    "joblib.dump(encoder, 'ordinal_encoder.pkl')  # Save for inference\n",
    "if cat_selected:\n",
    "    joblib.dump(ohe, 'onehot_encoder.pkl')   # Save for inference\n",
    "\n",
    "print(\"Final dataset prepared with one-hot encoded categorical features\")\n",
    "print(f\"Final feature count: {X_final.shape[1]}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
